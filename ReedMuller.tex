\documentclass[articleoptions={12pt,a4paper,oneside}]{beamerswitch}

\usepackage[english,russian]{babel}
\usepackage{microtype}
\usepackage{csquotes}
\usepackage{multicol}

\usepackage{unicode-math}

\articlelayout{frametitles=margin,maketitle}
\mode<article>{
    \usepackage[
        a4paper,
        inner=15mm,
        outer=50mm,
        top=20mm,
        bottom=25mm,
        marginparsep=5mm,
        marginpar=40mm
    ]{geometry}
}
\mode<handout>{\setbeameroption{show notes}}
\mode<beamer>{\setbeameroption{show notes on second screen}}

\usetheme{Berkeley}
%\usecolortheme[rgb={1,0.7137,0}]{stzructure}

\usefonttheme{professionalfonts}
\setmainfont[Ligatures=TeX]{CMU Serif}
\setsansfont[Ligatures=TeX]{CMU Sans Serif}
\setmonofont{FiraMono}

\setmathfont{latinmodern-math.otf}
\setmathfont[range=\varnothing]{Asana-Math.otf}
\setmathfont[range=\int]{latinmodern-math.otf}

\def\UrlFont{\tt\small}

\usepackage{graphicx}
\graphicspath{{figures/}}

\setbeamerfont{note page}{size=\footnotesize}
\addtobeamertemplate{note page}{\setbeamerfont{itemize/enumerate subbody}{size=\footnotesize}}{}

\title{Код Рида-Маллера}
\author[]{Илья Коннов}
\institute[ВШЭ]{{Факультет компьютерных наук}\and{Высшая Школа Экономики}}
\date{\today}
\logo{\includegraphics[height=0.8cm]{cshse.pdf}}

\DeclareMathOperator{\RM}{RM}
\DeclareMathOperator{\Eval}{Eval}
\newcommand{\comment}[1]{\mode<article>{#1}\note[item]{#1}}

\begin{document}

\begin{frame}
    \maketitle
    
    \comment{Если вы смотрите презентацию, то на сером фоне справа иногда видны некоторые ценные комментарии, для которых поля слайда оказались слишком узки. Если вы читаете pdf-ку, то эти комментарии уже находятся в самом подходящем для них месте в тексте (а в правых полях видны заголовки слайдов). Если вы смотрите мой доклад и видите этот текст, то что-то пошло серьёзно не так. Да, у этого одного файла есть три разные версии.}
\end{frame}

\mode<article>{
    \tableofcontents
    \newpage
}

\section{Введение}
\begin{frame}{Введение}
    Описаны Дэвидом Маллером (автор идеи) и Ирвингом Ридом (автор метода декодирования) в сентябре 1954 года.
    
    Обозначаются как $\RM(r, m)$, где $r$ — ранг, а $2^m$ — длина кода. Кодирует сообщения длиной $k = \sum_{i=0}^{r} C_m^i$ при помощи $2^m$ бит.
    
    Традиционно, считается что коды бинарные и работают над битами, т.е. $ℤ₂$.
    
    Соглашение: сложение векторов $u, v ∈ ℤ_2^n$ будем обозначать как $u ⊕ v = (u_1 + v_1, u_2 + v_2, …, u_n + v_n)$.
\end{frame}

\begin{frame}{Булевы функции и многочлен Жегалкина}
    Всякую булеву функцию можно записать при помощи таблицы истинности
    \[
        \begin{array}{cc | c}
            x & y & f(x, y) \\\hline
            0 & 0 & 1 \\
            0 & 1 & 0 \\
            1 & 0 & 0 \\
            1 & 1 & 0
        \end{array}
    \]
    
    И при помощи многочлена Жегалкина:
    \[
        f(x, y) = xy + x + y + 1
    \]
\end{frame}

\begin{frame}{Многочлены Жегалкина}
    В общем случае, многочлены будут иметь следующий вид:
    \[
        f(x_1, x_2, …, x_m) = \sum_{S ⊆ \{1, …, m\}} c_S \prod_{i ∈ S} x_i
    \]

    Например, для $m = 2$: $ f(x_1, x_2) = c_1 \cdot x_1x_2 + c_2 \cdot x_1 + c_3 \cdot x_2 + c_4\cdot1$
    
    Всего $n = 2^m$ коэффициентов для описания каждой функции.
\end{frame}

\begin{frame}{Функции небольшой степени}
    Рассмотрим функции, степень многочленов которых не больше $r$:
    \[
        \{ f(x_1, x_2, …, x_m) \mid \deg f ≤ r \}
    \]
    
    Каждую можно записать следующим образом:
    \[
        f(x_1, x_2, …, x_m) = \sum_{\substack{S ⊆ \{1, …, m\}\\|S| ≤ r}} c_S \prod_{i ∈ S} x_i
    \]
    В каждом произведении используется не больше $r$ переменных.
    
    \comment{Замечу, что при $S = \emptyset$, мы считаем, что $\prod_{i∈S} x_i = 1$, таким образом всегда появляется свободный член.}

    Сколько тогда всего коэффициентов используется?
    \[
        k = C_m^0 + C_m^2 + … + C_m^r = \sum_{i=0}^r C_m^i
    \]
    
    \comment{
        Если говорить несколько проще, то для составления многочленов мы сложим сначала одночлены ($x + y + z$), затем произведения одночленов ($xy + yz + xz$) и т.д. вплоть до $r$ множителей. Тогда легко видеть, почему $k$ именно такое: мы складываем все возможные перестановки сначала для 0 переменных, потом для одной, двух, и так до всех $r$
    }
\end{frame}

\section{Кодирование}
\begin{frame}{Идея кодирования}
    Пусть каждое сообщение (длины $k$) — коэффициенты некоторого многочлена от $m$ переменных степени не больше $r$.
    
    Тогда мы можем его представить при помощи $2^n$ бит, подставив все возможные комбинации переменных (ведь рассматриваем многочлены над $ℤ₂$).
    
    Таким образом получим таблицу истинности, из которой позднее сможем восстановить исходный многочлен, а вместе с ним и сообщение.
\end{frame}

\begin{frame}{Пример}
    \begin{itemize}
        \item $r = 1$ (степень многочлена), $m = 2$ (переменных).\\Это $\RM(1, 2)$. \\
        \item Тогда наш многочлен: $f(x, y) = c_1 x + c_2 y + c_3$.
        \item Сообщение: $\mathtt{101}$, тогда $f(x, y) = x + 0 + 1$.
        \item Подставим всевозможные комбинации:
            \[
                \begin{array}{cc | c}
                    x & y & f(x, y) \\\hline
                    0 & 0 & 1 \\
                    0 & 1 & 1 \\
                    1 & 0 & 0 \\
                    1 & 1 & 0
                \end{array}
            \]
        \item Получили код: $\mathtt{1100}$.
    \end{itemize}
\end{frame}
\begin{frame}{Декодирование когда потерь нет}
    \comment{Или как можно декодировать код, в самых простых ситуациях. Этот пример — продолжение предыдущего.}
    
    \begin{itemize}
        \item Мы получили код: $\mathtt{1100}$
        \item \begin{multicols}{2}
            Представим таблицу истинности.
            \columnbreak
            \[
            \begin{array}{cc | c}
                x & y & f(x, y) \\\hline
                0 & 0 & 1 \\
                0 & 1 & 1 \\
                1 & 0 & 0 \\
                1 & 1 & 0
            \end{array}
            \]
        \end{multicols}
        \item \begin{multicols}{2}
            Подстановками в ${f(x, y) = c_1 x + c_2 y + c_3}$ получим СЛАУ.
            \columnbreak
            \[
            \left\{\begin{array}{c c c c c c c}
                    & &     & & c_3 &=& 1 \\
                    & & c_2 &+& c_3 &=& 1 \\
                c_1 &+&     & & c_3 &=& 0 \\
                c_1 &+& c_2 &+& c_3 &=& 0
            \end{array}\right.
            \]
        \end{multicols}
        \item $c_1 = 1, c_2 = 0, c_3 = 1$, исходное сообщение: \texttt{101}.
    \end{itemize}
\end{frame}

\section{Свойства и параметры кода}
\begin{frame}{Доказательство линейности}
    \comment{
        Хотим показать, что этот код является линейным, т.е. что его кодовые слова образуют линейное пространство,
        и у нас есть изоморфизм из пространства сообщений ($ℤ₂^k$) в пространство слов ($ℤ₂^m$).
        
        Для этого необходимо немного формализовать всё описанное раньше.
    }
    
    Пусть $C(x)$ кодирует сообщение $x ∈ ℤ₂^k$ в код $C(x) ∈ \symbb{Z}₂^m$.
    \[
        C(x) = (p_x(a_i) \mid a_i ∈ ℤ₂^m)
    \]
    где $p_x(a_i)$ — соответствующий сообщению $a_i$ многочлен. Перебирая все $a_i$ получаем упорядоченный набор его значений. Это и будет кодом.
    
    Причём $p_x$ берёт в качестве своих коэффициентов биты из $x$. Поскольку многочлены степени не выше $r$ образуют линейное пространство, то $p_{(x ⊕ y)} = p_x + p_y$.
    
    \comment{
        Напомню, что базис пространства многочленов выглядит примерно так: $1, x_1, x_2, x_1x_2$ (для двух переменных, степени не выше 2). Поскольку мы работает в поле $ℤ₂$, здесь нету $x_1^2$ и $x_2^2$ ($a^2 = a$).

        Чтобы преобразовать сообщение в многочлен, мы берём каждый бит сообщения и умножаем его на соответствующий базисный вектор. Очевидно, такое преобразование будет изоморфизмом. Именно поэтому $p_{(x + y)} = p_x + p_y$.

        Обратите внимание, что $x$ это не просто число ($ℤ_{2^k}$) и мы рассматриваем его биты, а реально вектор битов ($ℤ₂^k$). У него операция сложения побитовая ($⊕$).
    }

    Тогда:
    \[
        C(x ⊕ y)_i = p_{(x⊕y)}(a_i) = p_x(a_i) + p_y(a_i) = C(x)_i + C(y)_i
    \]
    т.е. $∀x, y\quad C(x ⊕ y) = C(x) + C(y)$, ч.т.д.
    
    \comment{
        Для краткости, я использую запись $C(x)_i$ для $i$-го элемента вектора $C(x)$. Поскольку $i$ произвольное, то и весь вектор получился равен.
        
        Таким образом этот код действительно линейный и к нему применимы уже известные теоремы!
    }
\end{frame}

\begin{frame}{Последствия линейности}
    \begin{enumerate}
        \item Существует порождающая матрица $G$.
            \[ C(x) = x_{1×k}G_{k×n} = c_{1×n}\]
            \comment{Так можно кодировать сообщения $x$ в коды $c$. Но искать её мы не будем, обойдёмся одними многочленами, это интереснее.}
        \item Минимальное растояние будет равно минимальному весу Хемминга среди всех кодов.
            \comment{Вес Хэмминга вектора — количество в нём ненулевых элементов.}
            \[ d = \min_{\substack{c∈C\\c≠0}} w(c) \]
            \comment{Доказательство очень просто: минимальное расстояние — вес разности каких-то двух различных кодов, но разность двух кодов тоже будет кодом, т.к. мы в линейном пространстве. Значит достаточно найти минимальный вес, но не учитывая нулевой вектор, т.к. разность равна нулю тогда и только тогда, когда коды равны.}
        \item Корректирующая способность:
            \[ t = \left\lfloor \frac{d - 1}{2} \right\rfloor \]
    \end{enumerate}
    \comment{Однако мы ещё не знаем как выглядят наши коды (как выглядят таблицы истинности функций степени не больше $r$?). А значит не можем ничего сказать про минимальное расстояние.}
\end{frame}

\subsection{Конструкция Плоткина}

\begin{frame}{Конструкция Плоткина: многочлены}
    Хотим понять как выглядят кодовые слова.

    \begin{itemize}
        \item Код — таблица истинности функции $f(x_1, …, x_m) ∈ \RM(r, m)$, причём $\deg f ≤ r$.
            \comment{Порядок очевидно не больше $r$, потому что это условие для включения в пространство кодов $\RM(r, m)$.}

        \item Разделим функцию по $x_1$: $f(x_1, …, x_m) = g(x_2, …, x_m) + x_1 h(x_2, …, x_m)$.
            \comment{Теперь у нас есть две функции от меньшего числа аргументов. Очевидно, так можно сделать всегда, когда m > 1.}

        \item Заметим, что $\deg f ≤ r$, а значит $\deg g ≤ r$ и $\deg h ≤ r-1$.
    \end{itemize}
\end{frame}

\begin{frame}{Конструкция Плоткина: таблица истинности}
    \comment{Теперь рассмотрим те же функции, но со стороны их таблиц истинности. Нам же интересны именно коды, а они как раз очень тесно связаны с этими таблицами.}

    Ранее: $f(x_1, …, x_m) = g(x_2, …, x_m) + x_1 h(x_2, …, x_m)$.

    \begin{itemize}
        \item Заметим, что таблица истинности $f$ состоит из двух частей: при $x_1 = 0$ и при $x_1 = 1$.
            \[
                \Eval(f) = \begin{pmatrix}
                    \Eval^{[x_1 = 0]}(f) \\\hline
                    \Eval^{[x_1 = 1]}(f)
                \end{pmatrix}
            \]
            \comment{
                Здесь я очень резко ввожу обозначения для таблицы истинности, но они больше не пригодятся.
                Вообще-то говоря, это не матрица, а вектор длины $2^m$ (число аргументов), поскольку порядок аргументов всегда фиксирован и нам его хранить не нужно.
                В любом случае, $\Eval(f)$ — таблица для всей функции, $\Eval^{[x_1 = 0]}(f)$ — кусок таблицы при $x_1 = 0$, $\Eval^{[x_1 = 1]}(f)$ — кусок таблицы при $x_1 = 1$.
            }

        \item Причём $\Eval^{[x_1 = 0]}(f) = \Eval(g)$, а $\Eval^{[x_1 = 0]}(f) ⊕ \Eval^{[x_1 = 1]}(f) = \Eval(h)$.
            \comment{
                Это всё следует из ранее полученного утверждения. Если мы подставим $x_1 = 0$, то останется только $g$ — первое равенство очевидно. Если же мы рассмотрим $\Eval^[x_1 = 1](f)$, то получим $\Eval(g + h)$, но если туда прибавить ещё раз $\Eval(g)$, то останется только $\Eval(h)$ (поскольку $1 + 1 = 0$ в $ℤ₂$) — получили второе равенство.
            }

        \item Таким образом, $\Eval(f) = \left(\Eval(g) \mid \Eval(g) ⊕ \Eval(h)\right)$
    \end{itemize}
\end{frame}

\begin{frame}{Конструкция Плоткина: вывод}
    \comment{Теперь собираем всё это в одно важное утверждение.}

    Если дана $f(x_1, …, x_m)$, причём $\deg f ≤ r$, то можно её разделить:
        \[
            f(x_1, …, x_m) = g(x_2, …, x_m) + x_1h(x_2, …, x_m)
        \]
    \comment{Причём мы уже знаем, что $\deg g ≤ r$ и $\deg h ≤ r-1$, если $\deg f ≤ r$ }

    \medskip

    Также известно, что $\Eval(f) = \left(\Eval(g) \mid \Eval(g) ⊕ \Eval(h)\right)$.

    \medskip

    Заметим, что $\Eval(f)$ – кодовое слово (как и для $g, h$).\newline
    Тогда: \begin{tabular}[t]{l l}
        $ c = \Eval(f) ∈ \RM(r, m) $     & (т.к. $ \deg f ≤ r $) \\
        $ u = \Eval(g) ∈ \RM(r, m-1) $   & (т.к. $ \deg g ≤ r $) \\
        $ v = \Eval(h) ∈ \RM(r-1, m-1) $ & (т.к. $ \deg h ≤ r-1 $) \\
    \end{tabular}

    \comment{
        Напомню, что $\RM(r, m)$ включает в себя \textbf{все} функции (их таблицы истинности, если точнее) от $m$ аргументов и степени не выше $r$. Очевидно, наши годятся.
    }

    \medskip

    \textbf{Утверждение: }
    Для всякого кодового слова $c ∈ \RM(r, m)$ можно найти $u ∈ \RM(r, m-1)$ и $v ∈ \RM(r-1, m-1)$, такие что $c = (u \mid u + v)$.

    \comment{
        Что здесь важно отметить — оба наших новых кодовых слова $u, v$ получились «меньше», чем исходное $c$.

        Это позволяет, во-первых, устраивать индукцию по $m$, чем мы скоро и займёмся.
        Во-вторых, это позволяет легко строить большие порождающие матрицы, но мы этим не будем заниматься.
    }
\end{frame}

\subsection{Минимальное расстояние}

\begin{frame}{Минимальное расстояние}
    Хотим найти минимальное расстояние для кода $\RM(r, m)$
    \[
        d = \min_{c∈C, c≠0} w(c)
    \]

    Предположим, что $d = 2^{m - r}$ и докажем по индукции.

    \textbf{База:} $\RM(0, m)$ — единственный бит потворён $2^m$ раз.
    Очевидно, $w(\underbrace{\mathtt{11…1}}_{2^m}) = 2^m = 2^{m-0} ≥ 2^{m-r}$.

    \comment{
        Случай $\RM(0, m)$ — очень скучный. Здесь длина сообщения равна $k = \sum_{i=0}^r C_m^i = C_m^0 = 1$, а длина кода $n = 2^m$. Причём мы просто берём один бит (соответсвует функции $f(x_1, …, x_m) = 0$ или $f(x_1, …, x_m) = 1$) и повторяем его $2^m$ раз (в таблице истинности).

        Замечу, что не рассматриваю второй случай $w(\mathtt{00…0})$, поскольку он нам не нужен для расчёта минимального расстояния. Вариант с нулевым вектором явно выкидывается, см. определение $d$ выше.
    }

    \textbf{Гипотеза:} Если $v∈\RM(r-1, m-1)$, то $w(v) ≥ 2^{m-r}$.

    \textbf{Шаг:} Хотим доказать для $c ∈ \RM(r, m)$.
    \begin{align*}
    w(c) &= w((u \mid u ⊕ v))
            \stackrel{(1)}{=} w(u) + w(u ⊕ v)
        ≥\\&\stackrel{(2)}{≥} w(u) + \left(w(v) - w(u)\right)
            = w(v)
            \stackrel{IH}{≥} 2^{m-r} \QED
    \end{align*}

    \comment{
        Теперь немного объяснений.

        Переход (1): $w((x \mid y)) = w(x) + w(y)$. Вес это всего лишь число ненулевых элементов, поэтому нет разницы как мы будем группировать части вектора.

        Переход (2): $w(u ⊕ v) ≥ w(v) - w(u)$. Если у нас в $v$ стоит $w(v)$ бит, то прибавив к нему $u$, мы сможем изменить (обнулить) не больше $w(u)$ бит. Возможно появится больше единиц, но нас интересует нижняя граница.

        Переход (IH): предположение индукции в чистом виде.
    }
\end{frame}

\subsection*{}

\begin{frame}{Свойства и параметры}
    Для бинарного кода $\RM(r, m)$:
    \begin{itemize}
        \item $r ≤ m$
        \item Длина кода: $2^m$
        \item Длина сообщения: $k = \sum_{i=0}^r C_m^i$
        \item Минимальное расстояние: $d = 2^{m - r}$
        \item Корректирующая способность: $t = 2^{m - r - 1} - 1$ \comment{
            поскольку $t = \left\lfloor\frac{d - 1}{2}\right\rfloor = \left\lfloor\frac{2^{m - r}}{2} - \frac{1}{2}\right\rfloor = \left\lfloor2^{m - r - 1} - 0.5\right\rfloor = 2^{m - r - 1} - 0.5$
        }
        \item Существует порождающая матрица $G$ для кодирования
    \end{itemize}
\end{frame}

\section{Декодирование}

\begin{frame}{Если потери есть}
    Этот код является линейным, к нему применимы все обычные (и неэффективные методы):
    \begin{itemize}
        \item 
    \end{itemize}
\end{frame}

\section{Источники}
Бонусный раздел, который не включён в основную презентацию, но может быть очень полезен.

\begin{enumerate}
    \item \url{https://arxiv.org/pdf/2002.03317.pdf} — топчик.
    \item \url{http://dha.spb.ru/PDF/ReedMullerExamples.pdf} — очень хорошо и подробно, но используется подход через матрицы, а не через полиномы, а это не весело.
    \item \url{https://en.wikipedia.org/wiki/Reed–Muller_code} — кратко, чётко, понятно, но не описано декодирование.
    \item \url{https://ru.bmstu.wiki/Коды\_Рида-Маллера} — в целом всё есть, но написано очень непонятно;
\end{enumerate}

\end{document}
